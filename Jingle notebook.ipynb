{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Music Compositor using LangGraph\n",
    "\n",
    "## Overview\n",
    "This tutorial demonstrates how to build an AI-powered music composition system using LangGraph, a framework for creating workflows with language models. The system generates musical compositions based on user input, leveraging various components to create melody, harmony, rhythm, and style adaptations.\n",
    "\n",
    "## Motivation\n",
    "Creating music programmatically is a fascinating intersection of artificial intelligence and artistic expression. This project aims to explore how language models and graph-based workflows can be used to generate coherent musical pieces, providing a unique approach to AI-assisted music composition.\n",
    "\n",
    "## Key Components\n",
    "1. State Management: Utilizes a `MusicState` class to manage the workflow's state.\n",
    "2. Language Model: Employs ChatOpenAI (GPT-4) for generating musical components.\n",
    "3. Musical Functions:\n",
    "   - Melody Generator\n",
    "   - Harmony Creator\n",
    "   - Rhythm Analyzer\n",
    "   - Style Adapter\n",
    "4. MIDI Conversion: Transforms the composition into a playable MIDI file.\n",
    "5. LangGraph Workflow: Orchestrates the composition process using a state graph.\n",
    "\n",
    "## Method\n",
    "1. The workflow begins by generating a melody based on user input.\n",
    "2. It then creates harmony to complement the melody.\n",
    "3. A rhythm is analyzed and suggested for the melody and harmony.\n",
    "4. The composition is adapted to the specified musical style.\n",
    "5. The final composition is converted to MIDI format.\n",
    "\n",
    "The entire process is orchestrated using LangGraph, which manages the flow of information between different components and ensures that each step builds upon the previous ones.\n",
    "\n",
    "## Conclusion\n",
    "This AI Music Compositor demonstrates the potential of combining language models with structured workflows to create musical compositions. By breaking down the composition process into discrete steps and leveraging the power of AI, we can generate unique musical pieces based on simple user inputs. This approach opens up new possibilities for AI-assisted creativity in music production and composition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import all necessary modules and libraries for the AI Music Collaborator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from typing import Dict, TypedDict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import music21\n",
    "from music21 import midi\n",
    "import tempfile\n",
    "import os\n",
    "import random\n",
    "from openai import AzureOpenAI\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Definition\n",
    "\n",
    "Define the MusicState class to hold the workflow's state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicState(TypedDict):\n",
    "    \"\"\"Define the structure of the state for the music generation workflow.\"\"\"\n",
    "    musician_input: str  # User's input describing the desired music\n",
    "    melody: str          # Generated melody\n",
    "    harmony: str         # Generated harmony\n",
    "    rhythm: str          # Generated rhythm\n",
    "    style: str           # Desired musical style\n",
    "    composition: str     # Complete musical composition\n",
    "    midi_file: str       # Path to the generated MIDI file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Initialization\n",
    "\n",
    "Initialize the Language Model (LLM) for generating musical components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"YOUR_API_KEY\"\n",
    "endpoint = \"YOUR_API_ENDPOINT\"\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-4o\",  # or your deployment\n",
    "    api_version=\"2024-08-01-preview\",  # or your api version\n",
    "    temperature=0,\n",
    "    api_key = api_key,\n",
    "    azure_endpoint=endpoint,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Functions\n",
    "\n",
    "Define the component functions for melody generation, harmony creation, rhythm analysis, style adaptation, and MIDI conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melody_generator(state: MusicState) -> Dict:\n",
    "    \"\"\"Generate a melody based on the user's input.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Generate a melody based on this input: {input}. Represent it as a string of notes in music21 format and only provide executable code nothing else.\"\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    melody = chain.invoke({\"input\": state[\"musician_input\"]})\n",
    "    return {\"melody\": melody.content}\n",
    "\n",
    "def harmony_creator(state: MusicState) -> Dict:\n",
    "    \"\"\"Create harmony for the generated melody.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Create harmony for this melody: {melody}. Represent it as a string of chords in music21 format and only provide executable code nothing else.\"\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    harmony = chain.invoke({\"melody\": state[\"melody\"]})\n",
    "    return {\"harmony\": harmony.content}\n",
    "\n",
    "def rhythm_analyzer(state: MusicState) -> Dict:\n",
    "    \"\"\"Analyze and suggest a rhythm for the melody and harmony.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Analyze and suggest a rhythm for this melody and harmony: {melody}, {harmony}. Represent it as a string of durations in music21 format and only provide executable code nothing else.\"\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    rhythm = chain.invoke({\"melody\": state[\"melody\"], \"harmony\": state[\"harmony\"]})\n",
    "    return {\"rhythm\": rhythm.content}\n",
    "\n",
    "def style_adapter(state: MusicState) -> Dict:\n",
    "    \"\"\"Adapt the composition to the specified musical style.\"\"\"\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Adapt this composition to the {style} style: Melody: {melody}, Harmony: {harmony}, Rhythm: {rhythm}. Provide the result in midi format and define a function to save the score and return the MIDI file path. Save the MIDI file and return the path. only provide executable code nothing else also dont include the backticks as well as I want to directly run it without any changes. \"\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    adapted = chain.invoke({\n",
    "        \"style\": state[\"style\"],\n",
    "        \"melody\": state[\"melody\"],\n",
    "        \"harmony\": state[\"harmony\"],\n",
    "        \"rhythm\": state[\"rhythm\"]\n",
    "    })\n",
    "    return {\"composition\": adapted.content}\n",
    "\n",
    "def midi_converter(state: MusicState) -> Dict:\n",
    "    \"\"\"Convert the composition to MIDI format and save it as a file.\"\"\"\n",
    "    # Retrieve the generated composition code from the state\n",
    "    composition_code = state[\"composition\"]\n",
    "    \n",
    "    # Initialize a dictionary to hold the execution context\n",
    "    exec_context = {}\n",
    "\n",
    "    try:\n",
    "        # Execute the composition code in a safe context\n",
    "        \n",
    "        exec(composition_code, exec_context)\n",
    "        midi_file_path = exec_context.get('midi_file_path')\n",
    "        return {\"midi_file\": midi_file_path}\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"midi_file\": f\"Error executing composition code: {str(e)}\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Construction\n",
    "\n",
    "Construct the LangGraph workflow for the AI Music Collaborator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StateGraph\n",
    "workflow = StateGraph(MusicState)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(\"melody_generator\", melody_generator)\n",
    "workflow.add_node(\"harmony_creator\", harmony_creator)\n",
    "workflow.add_node(\"rhythm_analyzer\", rhythm_analyzer)\n",
    "workflow.add_node(\"style_adapter\", style_adapter)\n",
    "workflow.add_node(\"midi_converter\", midi_converter)\n",
    "\n",
    "# Set the entry point of the graph\n",
    "workflow.set_entry_point(\"melody_generator\")\n",
    "\n",
    "# Add edges to connect the nodes\n",
    "workflow.add_edge(\"melody_generator\", \"harmony_creator\")\n",
    "workflow.add_edge(\"harmony_creator\", \"rhythm_analyzer\")\n",
    "workflow.add_edge(\"rhythm_analyzer\", \"style_adapter\")\n",
    "workflow.add_edge(\"style_adapter\", \"midi_converter\")\n",
    "workflow.add_edge(\"midi_converter\", END)\n",
    "\n",
    "# Compile the graph\n",
    "memory = MemorySaver()\n",
    "\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Workflow\n",
    "\n",
    "Execute the AI Music Collaborator workflow to generate a musical composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDI file saved at: romantic_melody.mid\n"
     ]
    }
   ],
   "source": [
    "# Define input parameters\n",
    "inputs = {\n",
    "    \"musician_input\": \"Create a happy piano piece in C major\",\n",
    "    \"style\": \"Romantic era\"\n",
    "}\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Invoke the workflow\n",
    "result = app.invoke(inputs, config)\n",
    "\n",
    "print(f\"MIDI file saved at: {result['midi_file']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
